# -*- coding: utf-8 -*-
"""CC_Placement_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10tDnXxU-MkaFclRLvfiSNplzTgbSrZ7N
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

train_data= pd.read_excel('/content/01 Train Data.xlsx')

test_data= pd.read_excel('/content/02 Test Data.xlsx')

train_data.head(2)

test_data.head(2)

train_data.columns

test_data.columns

train_data.info()

test_data.info()

train_data[train_data.duplicated()]

duplicate_emails = train_data[train_data.duplicated(subset='Email ID', keep=False)]
print(duplicate_emails)

train_data.drop_duplicates(subset='Email ID', keep='first',inplace=True)

train_data.head(2)

train_data.shape

test_data[test_data.duplicated()]

test_data.shape

train_data.isna().sum()

test_data.isna().sum()

columns_to_drop = ['Attendee Status','College Name','Price Tier', 'Group', 'Quantity','Ticket Type', 'Attendee #','Order Type','Currency','Total Paid','Fees Paid','Eventbrite Fees','Eventbrite Payment Processing','How did you come to know about this event?','Specify in "Others" (how did you come to know about this event)','Designation','Year of Graduation']
train_data.drop(columns=columns_to_drop, inplace=True)

train_data.head(2)

columns_to_drop = ['Attendee Status','College Name','Price Tier', 'Group', 'Quantity','Ticket Type', 'Attendee #','Order Type','Currency','Total Paid','Fees Paid','Eventbrite Fees','Eventbrite Payment Processing','How did you come to know about this event?','Specify in "Others" (how did you come to know about this event)','Designation','Year of Graduation']
test_data.drop(columns=columns_to_drop, inplace=True)

test_data.head(2)

train_data.shape

test_data.shape

train_data.isna().sum()

test_data.isna().sum()

print(train_data['Placement Status'].unique())

print(test_data['Placement Status'].unique())

# convert placement status values into integer
train_data['Placement Status'] = train_data['Placement Status'].replace({"Not placed": 0, "Placed": 1})

print(train_data['Placement Status'].unique())

sns.heatmap(train_data.corr(),annot=True)
plt.show()

# To predict the values of missing values in 'Placement Status' column of train_data

train_data_placement_known = train_data.dropna(subset=['Placement Status'])
train_data_placement_missing = train_data[train_data['Placement Status'].isnull()]

X_train = train_data_placement_known[['CGPA', 'Speaking Skills', 'ML Knowledge']]
y_train = train_data_placement_known['Placement Status']
X_test = train_data_placement_missing[['CGPA', 'Speaking Skills', 'ML Knowledge']]

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(X_train, y_train)

print(model.score(X_train,y_train))

predicted_placement_status = model.predict(X_test)

train_data_placement_missing['Placement Status'] = predicted_placement_status

train_data = pd.concat([train_data_placement_known, train_data_placement_missing])

train_data.head()

# Now using the train data to predict for the test data

from sklearn.model_selection import train_test_split
X_train = train_data_placement_known[['CGPA', 'Speaking Skills', 'ML Knowledge']]
y_train = train_data_placement_known['Placement Status']
X_test = test_data[['CGPA', 'Speaking Skills', 'ML Knowledge']]

# Model 1 = RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier

model1 = RandomForestClassifier()
model1.fit(X_train, y_train)

print(model1.score(X_train,y_train))

# Model 2 = LogisticRegression
from sklearn.linear_model import LogisticRegression

model2 = LogisticRegression()
model2.fit(X_train, y_train)

print(model2.score(X_train,y_train))

# Model 3 = SVM
from sklearn.svm import SVC

model3 = SVC(kernel='linear', C=1.0)

model3.fit(X_train, y_train)

print(model3.score(X_train,y_train))

#Model 4 = KNN
from sklearn.neighbors import KNeighborsClassifier

model4 = KNeighborsClassifier(n_neighbors=3)

model4.fit(X_train, y_train)

print(model4.score(X_train,y_train))

#Model 5 = DTC
from sklearn.tree import DecisionTreeClassifier

model5 = DecisionTreeClassifier(max_depth=13)

model5.fit(X_train, y_train)

print(model5.score(X_train,y_train))

#Model 6 = NaiveBAyesClassifier
from sklearn.naive_bayes import GaussianNB

model6 = GaussianNB()

model6.fit(X_train, y_train)

print(model6.score(X_train,y_train))

predicted_placement_status_test = model1.predict(X_test)

test_data['Placement Status'] = predicted_placement_status_test

test_data

predicted_probabilities = model1.predict_proba(X_test)

threshold = 0.5
predicted_placement_status = ['Placed' if prob[1] > threshold else 'Not Placed' for prob in predicted_probabilities]

# Adding the predicted "Placement Status" values to the test_data DataFrame
test_data['Predicted Placement Status'] = predicted_placement_status

# Final look of the data
test_data

# Downloading the Placement Status Output File
file_path = "/content/placement_prediction_status_test_output_file.xlsx"

test_data.to_excel(file_path, index=False)